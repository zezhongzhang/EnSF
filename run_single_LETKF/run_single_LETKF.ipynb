{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from functools import partial\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('display.width',300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "422506594c4a6fc8"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def rk4(xt, fn, t, dt):\n",
    "    k1 = fn(xt, t)\n",
    "    k2 = fn(xt + dt / 2 * k1, t + dt / 2)\n",
    "    k3 = fn(xt + dt / 2 * k2, t + dt / 2)\n",
    "    k4 = fn(xt + dt * k3, t + dt)\n",
    "    return xt + dt * (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
    "\n",
    "def lorenz96_drift(x, t):\n",
    "    return (torch.roll(x, -1) - torch.roll(x, 2))*torch.roll(x, 1) - x + 8\n",
    "\n",
    "def matrix_sqrt(matrix):\n",
    "    r\"\"\"\n",
    "    Power of a matrix using Eigen Decomposition.\n",
    "    \"\"\"\n",
    "    L, Q = torch.linalg.eigh(matrix)\n",
    "    return Q * torch.sqrt(L[None,:])\n",
    "\n",
    "def crps_batch(ensemble, state_true):\n",
    "    x_sort = torch.sort(ensemble,dim=0)[0]\n",
    "    result = torch.zeros_like(state_true)\n",
    "\n",
    "    for i in range(ensemble_size+1):\n",
    "        if i == 0:\n",
    "            bin_left = -100\n",
    "            bin_right = x_sort[i,:]\n",
    "        elif i==ensemble_size:\n",
    "            bin_left = x_sort[i-1,:]\n",
    "            bin_right = 100\n",
    "        else:\n",
    "            bin_left = x_sort[i-1,:]\n",
    "            bin_right = x_sort[i,:]\n",
    "\n",
    "        temp1 = (bin_right - bin_left) * (float(i)/ensemble_size)**2\n",
    "        temp2 = (bin_right - bin_left)* (1.0 - float(i)/ensemble_size)**2 * (state_true <= bin_left)\n",
    "        temp3 = (state_true - bin_left)* (float(i)/ensemble_size)**2 + (bin_right - state_true)* (1.0 - float(i)/ensemble_size)**2\n",
    "        result += temp1 * (state_true >= bin_right) + temp2 * (state_true <= bin_left) + temp3 * (state_true < bin_right) * (state_true > bin_left)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def rank_count(ensemble, target):\n",
    "    ensemble_size = ensemble.shape[0]\n",
    "    state_rank = torch.sum(ensemble > target[None ,:], dim=0)\n",
    "    count = np.array([torch.sum(state_rank==i).item() for i in range(ensemble_size+1)])\n",
    "    return count\n",
    "\n",
    "\n",
    "obs_fun = lambda x: torch.atan(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "fe8ffba525635d10"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing setting:\n",
      "\tdevice: \t\t\tcpu\n",
      "\tprint_step_info: \tTrue\n",
      "\tsave_result: \t\tTrue\n",
      "\tsave_plot: \t\t\tTrue\n",
      "\tclip_tol: \t\t\t50\n",
      "total run: 1\n"
     ]
    }
   ],
   "source": [
    "# computing setup\n",
    "# device = 'cuda'\n",
    "device = 'cpu'\n",
    "\n",
    "default_dtype = torch.float32\n",
    "\n",
    "save_dir = 'results'\n",
    "print_step_info = True\n",
    "save_result = True\n",
    "save_plot = True\n",
    "\n",
    "# L96 clip value\n",
    "clip_tol = 50\n",
    "\n",
    "\n",
    "# computing setting\n",
    "print(f'computing setting:')\n",
    "print(f'\\tdevice: \\t\\t\\t{device}')\n",
    "print(f'\\tprint_step_info: \\t{print_step_info}')\n",
    "print(f'\\tsave_result: \\t\\t{save_result}')\n",
    "print(f'\\tsave_plot: \\t\\t\\t{save_plot}')\n",
    "print(f'\\tclip_tol: \\t\\t\\t{clip_tol}')\n",
    "\n",
    "###############################################################\n",
    "# load all parameters\n",
    "###############################################################\n",
    "param_combined = pd.read_csv('param_combined.csv')\n",
    "total_run = param_combined.shape[0]\n",
    "print(f'total run: {total_run}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "b7df4154a32c4613"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local run: [0]\n"
     ]
    }
   ],
   "source": [
    "# setup local run cases\n",
    "local_run_list = np.arange(total_run)\n",
    "print(f'local run: {local_run_list}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "df2fa71659b09f3c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_index: 90\n",
      "\tsave name: run_90_prob_3_method_0_init_0_seed_0\n",
      "\tproblem id: 3\n",
      "\t\tshock_dir: \t\t../data/shock_profile_1.npy\n",
      "\t\tdim_x: \t\t\t1000000\n",
      "\t\tobs_gap: \t\t10\n",
      "\t\tobs_sigma: \t\t0.05\n",
      "\t\tdt: \t\t\t0.01\n",
      "\tmethod id: 0\n",
      "\t\tensemble_size: \t20\n",
      "\t\tinflation: \t\t1.1\n",
      "\t\tr_loc: \t\t\t4\n",
      "\t\tneighbor_size: \t10\n",
      "step 0 DA:\n",
      "\t before DA: 4.2936\n",
      "\t  after DA: 2.9645\n",
      "\t      time: 326.4322\n",
      "step 10 DA:\n",
      "\t before DA: 2.9362\n",
      "\t  after DA: 2.4407\n",
      "\t      time: 332.8974\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    138\u001B[0m id_y \u001B[38;5;241m=\u001B[39m temp_loc \u001B[38;5;241m+\u001B[39m m \u001B[38;5;66;03m# local get index\u001B[39;00m\n\u001B[0;32m    139\u001B[0m dist_2_obs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(temp_loc\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m/\u001B[39m r_loc\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m )\n\u001B[1;32m--> 140\u001B[0m id_y \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfmod\u001B[49m\u001B[43m(\u001B[49m\u001B[43mid_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    141\u001B[0m id_y \u001B[38;5;241m=\u001B[39m id_y\u001B[38;5;241m.\u001B[39mlong()\n\u001B[0;32m    143\u001B[0m \u001B[38;5;66;03m# compute\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# temp local run data\n",
    "for local_run_id in local_run_list:\n",
    "    local_param = param_combined.loc[[local_run_id]]\n",
    "\n",
    "\n",
    "    # case_index\n",
    "    run_index = local_param['run_index'].iloc[0]\n",
    "\n",
    "    # problem parameter\n",
    "    problem_id = local_param['problem_id'].iloc[0]\n",
    "    seed = local_param['seed'].iloc[0]\n",
    "    init_id = local_param['init_id'].iloc[0]\n",
    "    dim_x = local_param['dim_x'].iloc[0]\n",
    "    shock_dir = local_param['shock_dir'].iloc[0]\n",
    "    obs_gap = local_param['obs_gap'].iloc[0]\n",
    "    obs_sigma = local_param['obs_sigma'].iloc[0]\n",
    "    dt = local_param['dt'].iloc[0]\n",
    "    N_step = local_param['N_step'].iloc[0]\n",
    "    state_init_all = np.load(f'../data/state_init_d_{dim_x}_rep_10.npy')\n",
    "    if shock_dir == shock_dir:\n",
    "        shock_profile = np.load(shock_dir)\n",
    "    else:\n",
    "        shock_profile = np.zeros(N_step)\n",
    "\n",
    "\n",
    "    # get param\n",
    "    method_id = local_param['method_id'].iloc[0]\n",
    "    ensemble_size = local_param['ensemble_size'].iloc[0]\n",
    "    inflation = local_param['inflation'].iloc[0]\n",
    "    r_loc = local_param['r_loc'].iloc[0]\n",
    "    neighbor_size = local_param['neighbor_size'].iloc[0]\n",
    "\n",
    "    save_name = f'run_{run_index}_prob_{problem_id}_method_{method_id}_init_{init_id}_seed_{seed}'\n",
    "\n",
    "\n",
    "    # print info\n",
    "    print(f'run_index: {run_index}')\n",
    "\n",
    "    # problem data\n",
    "    print(f'\\tsave name: {save_name}')\n",
    "    print(f'\\tproblem id: {problem_id}')\n",
    "    print(f'\\t\\tshock_dir: \\t\\t{shock_dir}')\n",
    "    print(f'\\t\\tdim_x: \\t\\t\\t{dim_x}')\n",
    "    print(f'\\t\\tobs_gap: \\t\\t{obs_gap}')\n",
    "    print(f'\\t\\tobs_sigma: \\t\\t{obs_sigma}')\n",
    "    print(f'\\t\\tdt: \\t\\t\\t{dt}')\n",
    "\n",
    "    # method data\n",
    "    print(f'\\tmethod id: {method_id}')\n",
    "    print(f'\\t\\tensemble_size: \\t{ensemble_size}')\n",
    "    print(f'\\t\\tinflation: \\t\\t{inflation}')\n",
    "    print(f'\\t\\tr_loc: \\t\\t\\t{r_loc}')\n",
    "    print(f'\\t\\tneighbor_size: \\t{neighbor_size}')\n",
    "\n",
    "\n",
    "    forward_fn = functools.partial(rk4, fn=lorenz96_drift, t=0, dt=dt)\n",
    "\n",
    "    temp_loc = torch.arange(neighbor_size*2 + 1, device=device) - neighbor_size\n",
    "    # set seed\n",
    "    torch.manual_seed(seed=seed)\n",
    "\n",
    "    # initial state\n",
    "    state_true = torch.from_numpy(state_init_all[init_id]).to(device=device, dtype=default_dtype)\n",
    "\n",
    "    # initial ensemble\n",
    "    # x_state = state_true + torch.randn(ensemble_size, dim_x, device=device) * init_sigma\n",
    "    x_state = torch.randn(ensemble_size, dim_x, device=device)\n",
    "\n",
    "    # info container var\n",
    "    rmse_all_step = []\n",
    "    rmse_post = []\n",
    "    cover_prob_post = []\n",
    "    ensemble_spread_post = []\n",
    "    crps_post = []\n",
    "    crps_prior = []\n",
    "    prior_rank_count_state = []\n",
    "    prior_rank_count_obs = []\n",
    "    post_rank_count_state = []\n",
    "    post_rank_count_obs = []\n",
    "\n",
    "    for i in range(N_step):\n",
    "        ###############################################################\n",
    "        # prediction step\n",
    "        ###############################################################\n",
    "        # true state forward in time\n",
    "        state_true = forward_fn(state_true)\n",
    "        # add shock to true state\n",
    "        shock_size = shock_profile[i]\n",
    "        if shock_size > 0:\n",
    "            state_true += torch.randn_like(state_true) * shock_size * torch.abs(state_true)  # relative to state value\n",
    "\n",
    "        # ensemble forward in time\n",
    "        x_state = forward_fn(x_state)\n",
    "\n",
    "        # state clip\n",
    "        x_state = torch.clip(x_state, min=-clip_tol, max=clip_tol)\n",
    "        ###############################################################\n",
    "\n",
    "        # get forecast info\n",
    "        x_est = torch.mean(x_state, dim=0)\n",
    "        rmse_temp_1 = torch.sqrt(torch.mean((x_est - state_true) ** 2)).item()\n",
    "        rmse_all_step.append([i, rmse_temp_1])\n",
    "\n",
    "        # divergence break\n",
    "        if rmse_temp_1 > 1000 or np.isnan(rmse_temp_1):\n",
    "            print('rmse:', rmse_temp_1)\n",
    "            print('break!')\n",
    "            break\n",
    "\n",
    "        ###############################################################\n",
    "        # update step\n",
    "        ###############################################################\n",
    "        if i % obs_gap == 0:\n",
    "            # get obs\n",
    "            obs_value = obs_fun(state_true) + obs_sigma*torch.randn_like(state_true)\n",
    "\n",
    "            t1 = time.time()\n",
    "            # update step\n",
    "            # LETKF\n",
    "            ###############################################################\n",
    "\n",
    "            Y = obs_fun(x_state) # (ensemble_size, dim_obs)\n",
    "\n",
    "            Y_mean = torch.mean(Y, dim=0)\n",
    "            Y = Y - Y_mean\n",
    "\n",
    "            X_mean = torch.mean(x_state, dim=0)\n",
    "            x_state = x_state - X_mean\n",
    "\n",
    "            # save prior for analysis\n",
    "            x_prior = x_state*inflation + X_mean\n",
    "\n",
    "\n",
    "            # localized update\n",
    "            ensemble_post = []\n",
    "            for m in range(dim_x):\n",
    "                # observation localization\n",
    "                id_y = temp_loc + m # local get index\n",
    "                dist_2_obs = torch.exp(temp_loc**2 / r_loc**2 )\n",
    "                id_y = torch.fmod(id_y, dim_x)\n",
    "                id_y = id_y.long()\n",
    "\n",
    "                # compute\n",
    "                X_local = x_state[:, [m]] # (ensemble_size, dim_x_loc)\n",
    "                Y_local = Y[:, id_y] # (ensemble_size, dim_obs_loc)\n",
    "\n",
    "                # C = R^{-1} @ Y_local\n",
    "\n",
    "                C = Y_local / (obs_sigma**2 * dist_2_obs[None,:]) # (ensemble_size, dim_obs_loc)\n",
    "                # C = Y_local / (obs_sigma**2) # (ensemble_size, dim_obs_loc)\n",
    "\n",
    "                P_tilde = (ensemble_size - 1) / inflation * torch.eye(ensemble_size, device=device, dtype=default_dtype) + \\\n",
    "                          torch.matmul(C, Y_local.T) # ()\n",
    "                P_tilde = torch.linalg.inv(P_tilde) # (ensemble_size, ensemble_size)\n",
    "                # print(P_tilde)\n",
    "\n",
    "                W = (ensemble_size-1) * P_tilde\n",
    "                W = matrix_sqrt(W) # (ensemble_size, ensemble_size)\n",
    "\n",
    "                w = torch.matmul(torch.matmul((obs_value[id_y] - Y_mean[id_y])[None,:] , C.T ) , P_tilde) # (1, ensemble_size)\n",
    "                # print(w)\n",
    "                # check\n",
    "                W = W + w[0] # (ensemble_size, ensemble_size)\n",
    "\n",
    "                X_local = torch.matmul(W , X_local) # (ensemble_size, dim_x_loc)\n",
    "\n",
    "                X_local = X_local + X_mean[m] # (ensemble_size, dim_x_loc)\n",
    "\n",
    "                ensemble_post.append(X_local) # save analyzed local grid point\n",
    "\n",
    "            x_state = torch.cat(ensemble_post, dim=1) #mxn\n",
    "            ###############################################################\n",
    "            t2 = time.time()\n",
    "\n",
    "            ###############################################################\n",
    "            # get info\n",
    "            # rmse\n",
    "            x_est = torch.mean(x_state, dim=0)\n",
    "            rmse_temp_2 = torch.sqrt(torch.mean((x_est - state_true) ** 2)).item()\n",
    "            if print_step_info:\n",
    "                print(f'step {i} DA:')\n",
    "                print(f'\\t before DA: {rmse_temp_1:.4f}')\n",
    "                print(f'\\t  after DA: {rmse_temp_2:.4f}')\n",
    "                print(f'\\t      time: {t2 - t1:.4f}')\n",
    "\n",
    "            rmse_all_step.append([i, rmse_temp_2])\n",
    "            rmse_post.append([i, rmse_temp_2])\n",
    "\n",
    "            # cover prob\n",
    "            q_upper = torch.quantile(x_state, q=0.975, dim=0)\n",
    "            q_lower = torch.quantile(x_state, q=0.025, dim=0)\n",
    "            cover_prob = torch.mean(1.0*(state_true <= q_upper) * (state_true >=q_lower)).item()\n",
    "            cover_prob_post.append(cover_prob)\n",
    "\n",
    "            # spread\n",
    "            ensemble_var = torch.var(x_state, dim=0)\n",
    "            ensemble_spread = torch.sqrt(torch.mean(ensemble_var)).item()\n",
    "            ensemble_spread_post.append(ensemble_spread)\n",
    "\n",
    "            # crps\n",
    "            crps = crps_batch(ensemble=x_state, state_true=state_true).mean().item()\n",
    "            crps_post.append(crps)\n",
    "            crps = crps_batch(ensemble=x_prior, state_true=state_true).mean().item()\n",
    "            crps_prior.append(crps)\n",
    "\n",
    "            # ranked hist\n",
    "            state_rank = rank_count(ensemble=x_prior, target=state_true)\n",
    "            prior_rank_count_state.append(state_rank)\n",
    "            state_rank = rank_count(ensemble=obs_fun(x_prior), target=obs_value)\n",
    "            prior_rank_count_obs.append(state_rank)\n",
    "\n",
    "            state_rank = rank_count(ensemble=x_state, target=state_true)\n",
    "            post_rank_count_state.append(state_rank)\n",
    "            state_rank = rank_count(ensemble=obs_fun(x_state), target=obs_value)\n",
    "            post_rank_count_obs.append(state_rank)\n",
    "\n",
    "            ###############################################################\n",
    "        ###############################################################\n",
    "    print(f'{save_name}:\\n\\tfinal rmse:\\t{rmse_temp_2:.4f}')\n",
    "\n",
    "    rmse_all_step = np.array(rmse_all_step)\n",
    "    rmse_post = np.array(rmse_post)\n",
    "    cover_prob_post = np.array(cover_prob_post)\n",
    "    ensemble_spread_post = np.array(ensemble_spread_post)\n",
    "    crps_post = np.array(crps_post)\n",
    "    crps_prior = np.array(crps_prior)\n",
    "\n",
    "    prior_rank_count_state = np.stack(prior_rank_count_state, axis=0)\n",
    "    prior_rank_count_obs = np.stack(prior_rank_count_obs, axis=0)\n",
    "    post_rank_count_state = np.stack(post_rank_count_state, axis=0)\n",
    "    post_rank_count_obs = np.stack(post_rank_count_obs, axis=0)\n",
    "\n",
    "\n",
    "    result_temp = {'rmse_all_step': rmse_all_step,\n",
    "                   'rmse_post': rmse_post,\n",
    "                   'cover_prob_post': cover_prob_post,\n",
    "                   'ensemble_spread_post': ensemble_spread_post,\n",
    "                   'crps_post': crps_post,\n",
    "                   'crps_prior': crps_prior,\n",
    "                   'prior_rank_count_state':prior_rank_count_state,\n",
    "                   'prior_rank_count_obs':prior_rank_count_obs,\n",
    "                   'post_rank_count_state':post_rank_count_state,\n",
    "                   'post_rank_count_obs':post_rank_count_obs}\n",
    "\n",
    "    # plot\n",
    "    if save_plot:\n",
    "        results=result_temp\n",
    "        fig, axs = plt.subplots(nrows=2,ncols=4,figsize=(12,6))\n",
    "        # rmse\n",
    "        ax = axs[0,0]\n",
    "        rmse_all_step = results['rmse_all_step']\n",
    "        rmse_post = results['rmse_post']\n",
    "        ax.plot(rmse_all_step[:,0],rmse_all_step[:,1],alpha=0.3)\n",
    "        ax.plot(rmse_post[:,0],rmse_post[:,1],'-')\n",
    "        ax.set_title('rmse_post')\n",
    "        ax.grid()\n",
    "\n",
    "        # cover_prob_post\n",
    "        ax = axs[0,1]\n",
    "        cover_prob_post = results['cover_prob_post']\n",
    "        ax.plot(rmse_post[:,0],cover_prob_post,'-')\n",
    "        ax.set_title('cover_prob_post')\n",
    "        ax.grid()\n",
    "\n",
    "        # ensemble_spread_post\n",
    "        ax = axs[1,0]\n",
    "        ensemble_spread_post = results['ensemble_spread_post']\n",
    "        ax.plot(rmse_post[:,0], ensemble_spread_post,'-')\n",
    "        ax.set_title('ensemble_spread_post')\n",
    "        ax.grid()\n",
    "\n",
    "        # crps\n",
    "        ax = axs[1,1]\n",
    "        crps_post = results['crps_post']\n",
    "        crps_prior = results['crps_prior']\n",
    "        ax.plot(rmse_post[:,0],crps_post,'-',label='post')\n",
    "        ax.plot(rmse_post[:,0],crps_prior,'-',label='prior')\n",
    "        ax.set_title('crps')\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "\n",
    "        name_all = ['prior_rank_count_state', 'prior_rank_count_obs', 'post_rank_count_state', 'post_rank_count_obs']\n",
    "        axs_all = [axs[0,2], axs[0,3], axs[1,2], axs[1,3]]\n",
    "\n",
    "        for i, name in enumerate(name_all):\n",
    "            data = results[name]\n",
    "            data = data / np.sum(data, axis=1, keepdims=True)\n",
    "            data = data[50:,:]\n",
    "            data = np.mean(data, axis=0)\n",
    "            ax = axs_all[i]\n",
    "            ax.bar(x=np.arange(len(data)),height=data)\n",
    "            ax.set_title(name)\n",
    "        fig.suptitle(save_name, fontsize=20)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f'{save_dir}/plot_{run_index}.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # save result\n",
    "    if save_result:\n",
    "        np.save(f'{save_dir}/result_{run_index}.npy', result_temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "17b0c284da2a1894"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}